(negated <- series %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% negation_words) %>%
inner_join(AFINN, by = c(word2 = "word")) %>%
count(word1, word2, score, sort = TRUE) %>%
ungroup()
)
negated %>%
mutate(contribution = n * score) %>%
arrange(desc(abs(contribution))) %>%
group_by(word1) %>%
top_n(10, abs(contribution)) %>%
ggplot(aes(drlib::reorder_within(word2, contribution, word1), contribution, fill = contribution > 0)) +
geom_bar(stat = "identity", show.legend = FALSE) +
xlab("Words preceded by 'not'") +
ylab("Sentiment score * # of occurrances") +
drlib::scale_x_reordered() +
facet_wrap(~ word1, scales = "free") +
coord_flip()
library(tidyverse)
library(ggplot2movies)
movies %>%
select(1:3) %>%
mutate(Long = ifelse(length >= 122.5, TRUE, FALSE))
movies %>%
select(1:3) %>%
mutate(Long = length >= 122.5)
movies %>%
select(1:3) %>%
mutate(Long = length >= 90)
movies %>%
select(1:3) %>%
mutate(Description = ifelse(length >= 122.5, "Long",
ifelse(length <= 40, "Short",
"Regular")))
movies %>%
select(1:3) %>%
mutate(Description = if(length >= 122.5, "Long"),
if(length <= 40, "Short"),
if(length > 40 & length < 122.5, "Short"))
movies %>%
select(1:3) %>%
mutate(Description = if(length >= 122.5, "Long"),
Description = if(length <= 40, "Short"),
Description = if(length > 40 & length < 122.5, "Short"))
movies %>%
select(1:3) %>%
mutate(Description = if(length >= 122.5, "Long")
movies %>%
select(1:3) %>%
mutate(Description = if(length >= 122.5) "Long")
read_csv("data/mydata.csv",
col_types = "cc_")
devtools::install_github("bradleyboehmke/harrypotter")
knitr::opts_chunk$set(echo = TRUE, collapse = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)      # data manipulation & plotting
library(stringr)        # text cleaning and regular expressions
library(tidytext)       # provides additional text mining functions
install.packages("tidytext")
library(tidyverse)      # data manipulation & plotting
library(stringr)        # text cleaning and regular expressions
library(tidytext)       # provides additional text mining functions
library(harrypotter)    # provides the first seven novels of the Harry Potter series
library(tm)
install.packages("tm")
?tm::DocumentTermMatrix()
?tm::DocumentTermMatrix
crude
data("crude")
tm::crude
library(tm)
data("crude")
crude
?tm::Corpus
Corpus(philosophers_stone)
tm::as.DocumentTermMatrix(philosophers_stone)
tm::as.VCorpus(philosophers_stone)
VCorpus(philosophers_stone)
VCorpus(DirSource(philosophers_stone))
VCorpus(VectorSource(philosophers_stone))
ps_dtm
library(tm)
ps_dtm <- VCorpus(VectorSource(philosophers_stone))
ps_dtm
inspect(ps_dtm)
inspect(ps_dtm[1])
inspect(ps_dtm[1,1])
ps_dtm
ps_dtm %>% inspect
ps_dtm[[1]]
inspect(ps_dtm[[1]])
Terms(ps_dtm)
data("AssociatedPress", package = "topicmodels")
install.packages("topic.models")
install.packages("topicmodels")
data("AssociatedPress", package = "topicmodels")
AssociatedPress
?tm::VectorSource
docs <- c("This is a text.", "This another one.")
(vs <- VectorSource(docs))
inspect(VCorpus(vs))
VectorSource(philosophers_stone) %>%
VCorpus()
ps_dtm <- VectorSource(philosophers_stone) %>%
VCorpus() %>%
DocumentTermMatrix()
inspect(ps_dtm)
terms <- Terms(ps_dtm)
head(terms)
terms
tail(terms)
?DocumentTermMatrix
library(tm)
ps_dtm <- VectorSource(philosophers_stone) %>%
VCorpus() %>%
DocumentTermMatrix(control = list(removeNumbers = TRUE,
stopwords = TRUE,
stemming = TRUE))
inspect(ps_dtm)
terms <- Terms(ps_dtm)
head(terms)
library(tm)
ps_dtm <- VectorSource(philosophers_stone) %>%
VCorpus() %>%
DocumentTermMatrix(control = list(removePunctuation = TRUE,
removeNumbers = TRUE,
stopwords = TRUE,
stemming = TRUE))
inspect(ps_dtm)
terms <- Terms(ps_dtm)
head(terms)
ps_dtm <- VectorSource(philosophers_stone) %>%
VCorpus() %>%
DocumentTermMatrix(control = list(removePunctuation = TRUE,
removeNumbers = TRUE,
stopwords = TRUE,
stripWhitespace = TRUE,
stemming = TRUE))
library(tm)
ps_dtm <- VectorSource(philosophers_stone) %>%
VCorpus() %>%
DocumentTermMatrix(control = list(removePunctuation = TRUE,
removeNumbers = TRUE,
stopwords = TRUE,
stripWhitespace = TRUE,
stemming = TRUE))
inspect(ps_dtm)
terms <- Terms(ps_dtm)
head(terms)
library(tm)
ps_dtm <- VectorSource(philosophers_stone) %>%
VCorpus() %>%
DocumentTermMatrix(control = list(removePunctuation = TRUE,
removeNumbers = TRUE,
stopwords = TRUE,
stemming = TRUE,
stripWhitespace = TRUE))
inspect(ps_dtm)
terms <- Terms(ps_dtm)
head(terms)
ps_tidy
ps_tidy <- tidy(ps_dtm)
ps_tidy
ps_tidy %>%
group_by(document) %>%
top_n(count, 5)
ps_tidy %>%
group_by(document)
ps_tidy %>%
group_by(document) %>%
top_n(count)
ps_tidy %>%
group_by(document) %>%
arrange(desc(n))
ps_tidy %>%
group_by(document) %>%
arrange(desc(count))
library(tm)
ps_dtm <- VectorSource(philosophers_stone) %>%
VCorpus() %>%
DocumentTermMatrix(control = list(removePunctuation = TRUE,
removeNumbers = TRUE,
stopwords = TRUE))
inspect(ps_dtm)
terms <- Terms(ps_dtm)
head(terms)
ps_tidy <- tidy(ps_dtm)
ps_tidy
ps_tidy %>%
group_by(document) %>%
arrange(desc(count))
ps_tidy %>%
group_by(document) %>%
top_n(count)
?top_n
ps_tidy %>%
group_by(document) %>%
top_n(count, 5)
ps_tidy %>%
group_by(document) %>%
top_n(5)
ps_tidy %>%
group_by(document) %>%
top_n(5) %>%
ggplot(aes(count, term)) +
geom_point() +
facet_wrap(~ document)
ps_tidy %>%
group_by(document) %>%
top_n(5) %>%
ggplot(aes(count, term)) +
geom_point() +
facet_wrap(~ document, scales = "free")
ps_tidy %>%
mutate(chapter = factor(document, levels = 1:17)) %>%
group_by(chapter) %>%
top_n(5) %>%
ggplot(aes(count, term)) +
geom_point() +
facet_wrap(~ chapter, scales = "free")
ps_tidy %>%
mutate(chapter = factor(document, levels = 1:17))
ps_tidy %>%
mutate(chapter = factor(document, levels = 1:17)) %>% str(.$chapter)
?factor
ps_tidy %>%
mutate(chapter = factor(document, ordered = TRUE)) %>%
group_by(chapter) %>%
top_n(5) %>%
ggplot(aes(count, term)) +
geom_point() +
facet_wrap(~ chapter, scales = "free")
ps_tidy %>%
mutate(chapter = factor(document, ordered = TRUE))
ps_tidy %>%
mutate(chapter = factor(document, ordered = TRUE)) %>% str(.$chapter)
?as.factor
ps_tidy %>%
mutate(chapter = as.factor(document, levels = 1:17))
ps_tidy %>%
mutate(chapter = factor(document, levels = 1:17))
mutate(chapter = factor(document, levels = 1:17)) %>% str(.$chapter)
ps_tidy %>%
mutate(chapter = factor(document, levels = 1:17)) %>%
group_by(chapter) %>%
top_n(5)
ps_tidy %>%
group_by(chapter) %>%
top_n(5)
ps_tidy %>%
group_by(document) %>%
top_n(5) %>%
ggplot(aes(count, term)) +
geom_point() +
facet_wrap(~ chapter, scales = "free")
ps_tidy %>%
group_by(document) %>%
top_n(5)
ps_tidy %>%
group_by(document) %>%
top_n(5) %>%
ggplot(aes(count, reorder(term, document))) +
geom_point() +
facet_wrap(~ chapter, scales = "free")
ps_tidy %>%
group_by(document) %>%
top_n(5) %>%
ggplot(aes(count, reorder(term, document))) +
geom_point()
ps_tidy %>%
group_by(document) %>%
top_n(5) %>%
ggplot(aes(count, reorder(term, document))) +
geom_point() +
facet_wrap(~ chapter, scales = "free")
ps_tidy %>%
group_by(document) %>%
top_n(5) %>%
ggplot(aes(count, order(term, document))) +
geom_point() +
facet_wrap(~ chapter, scales = "free")
ps_tidy %>%
group_by(document) %>%
top_n(5) %>%
ggplot(aes(count, term)) +
geom_point() +
facet_wrap(~ chapter, scales = "free")
ps_tidy %>%
group_by(document) %>%
top_n(5) %>%
ggplot(aes(count, term)) +
geom_point() +
facet_wrap(~ document, scales = "free")
ps_tidy %>%
group_by(document) %>%
top_n(5) %>%
mutate(document = factor(document, levels = 1:10)) %>%
ggplot(aes(count, term)) +
geom_point() +
facet_wrap(~ document, scales = "free")
ps_tidy %>%
group_by(document) %>%
top_n(5) %>%
mutate(document = factor(document, levels = 1:17)) %>%
ggplot(aes(count, term)) +
geom_point() +
facet_wrap(~ document, scales = "free")
group_by(document) %>%
top_n(5) %>%
mutate(document = factor(document, levels = 1:17))
ps_tidy %>%
group_by(document) %>%
top_n(5)
ps_tidy %>%
group_by(document) %>%
top_n(5) %>%
mutate(document = factor(as.numeric(document), levels = 1:17)) %>%
ggplot(aes(count, term)) +
geom_point() +
facet_wrap(~ document, scales = "free")
ps_tidy %>%
group_by(document) %>%
top_n(5) %>%
ungroup() %>%
mutate(document = factor(as.numeric(document), levels = 1:17)) %>%
ggplot(aes(count, term)) +
geom_point() +
facet_wrap(~ document, scales = "free")
devtools::install_github("dgrtwo/drlib")
ps_tidy %>%
group_by(document) %>%
top_n(5) %>%
ungroup() %>%
mutate(document = factor(as.numeric(document), levels = 1:17)) %>%
ggplot(aes(count, term)) +
geom_point() +
facet_wrap(~ document, scales = "free") +
drlib::scale_y_reordered()
ps_tidy %>%
group_by(document) %>%
top_n(5) %>%
ungroup() %>%
mutate(document = factor(as.numeric(document), levels = 1:17)) %>%
ggplot(aes(count, drlib::reorder_within(term, count, document))) +
geom_point() +
facet_wrap(~ document, scales = "free") +
drlib::scale_y_reordered()
```{r fig.align='center', fig.height=9}
ps_tidy %>%
group_by(document) %>%
top_n(5) %>%
ungroup() %>%
mutate(document = factor(as.numeric(document), levels = 1:17)) %>%
ggplot(aes(drlib::reorder_within(term, count, document)), count) +
geom_bar(stat = "identity") +
facet_wrap(~ document, scales = "free") +
drlib::scale_y_reordered() +
coord_flip()
ps_tidy %>%
group_by(document) %>%
top_n(5) %>%
ungroup() %>%
mutate(document = factor(as.numeric(document), levels = 1:17)) %>%
ggplot(aes(drlib::reorder_within(term, count, document)), count) +
geom_bar(stat = "identity")
ps_tidy %>%
group_by(document) %>%
top_n(5) %>%
ungroup() %>%
mutate(document = factor(as.numeric(document), levels = 1:17)) %>%
ggplot(aes(drlib::reorder_within(term, count, document), count)) +
geom_bar(stat = "identity") +
drlib::scale_y_reordered() +
coord_flip()
facet_wrap(~ document, scales = "free")
ps_tidy %>%
group_by(document) %>%
top_n(5) %>%
ungroup() %>%
mutate(document = factor(as.numeric(document), levels = 1:17)) %>%
ggplot(aes(drlib::reorder_within(term, count, document), count)) +
geom_bar(stat = "identity") +
drlib::scale_y_reordered() +
coord_flip() +
facet_wrap(~ document, scales = "free")
ps_tidy %>%
group_by(document) %>%
top_n(5) %>%
ungroup() %>%
mutate(document = factor(as.numeric(document), levels = 1:17)) %>%
ggplot(aes(drlib::reorder_within(term, count, document), count)) +
geom_bar(stat = "identity") +
drlib::scale_x_reordered() +
coord_flip() +
facet_wrap(~ document, scales = "free")
ps_tidy %>%
group_by(document) %>%
top_n(5) %>%
ungroup() %>%
mutate(document = factor(as.numeric(document), levels = 1:17)) %>%
ggplot(aes(drlib::reorder_within(term, count, document), count)) +
geom_bar(stat = "identity") +
xlab("Top 5 Common Words") +
drlib::scale_x_reordered() +
coord_flip() +
facet_wrap(~ document, scales = "free")
install.packages("quanteda")
quanteda::data_corpus_inaugural
knitr::opts_chunk$set(echo = TRUE, collapse = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)      # data manipulation & plotting
library(stringr)        # text cleaning and regular expressions
library(tidytext)       # provides additional text mining functions
library(harrypotter)    # provides the first seven novels of the Harry Potter series
library(tm)
VectorSource(philosophers_stone) %>%
VCorpus() %>%
quanteda::dfm(verbose = FALSE)
?quanteda::dfm
ps_dfm <- quanteda::dfm(verbose = FALSE)
ps_dfm <- quanteda::dfm(verbose = FALSE)
quanteda::as.corpus(philosophers_stone)
quanteda::as.DocumentTermMatrix(philosophers_stone)
ps_dfm <- quanteda::dfm(philosophers_stone)
ps_dfm <- quanteda::dfm(philosophers_stone, verbose = FALSE)
ps_dfm
tidy(ps_dfm)
?tm::findAssocs()
?tm::findAssocs
quanteda::bootstrap_dfm
?quanteda::bootstrap_dfm
ps_tidy <- tidy(ps_dfm)
ps_tidy
ps_tidy %>%
cast_dfm(term, document, count)
ps_tidy %>%
cast_dfm(term, document, count) %>%
bootstrap_dfm(n = 3)
ps_tidy %>%
cast_dfm(term, document, count) %>%
quanteda::bootstrap_dfm(n = 3)
ps_tidy %>%
cast_dfm(term, document, count) %>%
quanteda::as.corpus()
ps_tidy %>%
cast_dfm(term, document, count) %>%
quanteda::as.character.corpus()
ps_tidy %>%
cast_dfm(term, document, count) %>%
quanteda::textmodel_wordscores()
?quanteda::textmodel_wordscores
ps_tidy %>%
cast_dfm(term, document, count) %>%
quanteda::textmodel_wordscores(y = seq(0, 1, length.out = 17))
seq(0, 1, length.out = 17)
seq(-1.5, 1.5, .75)
ps_tidy %>%
cast_dfm(term, document, count) %>%
quanteda::textmodel_wordscores(y = 1)
ps_tidy %>%
cast_dfm(term, document, count) %>%
quanteda::textplot_scale1d()
ps_tidy %>%
cast_dfm(term, document, count) %>%
quanteda::textplot_scale1d()
?quanteda::textplot_scale1d
c(rep(NA, 4), -1, 1, rep(NA, 8))
ps_tidy %>%
cast_dfm(term, document, count)
ps_tidy %>%
cast_dtm(term, document, count)
ps_tidy %>%
cast_sparse(term, document, count)
ps_tidy %>%
cast_sparse(term, document, count) %>%
dim
VectorSource(philosophers_stone) %>%
VCorpus()
VectorSource(philosophers_stone) %>%
VCorpus() %>% .[[1]]
# turning philosophers_stone into a corpus
ps_corpus <- VectorSource(philosophers_stone) %>%
VCorpus()
ps_corpus
ps_corpus[[1]]
ps_tidy <- tidy(ps_corpus)
ps_tidy
install.packages("tm.plugin.webmining")
knitr::opts_chunk$set(echo = TRUE, collapse = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)      # data manipulation & plotting
library(stringr)        # text cleaning and regular expressions
library(tidytext)       # provides additional text mining functions
library(harrypotter)    # provides the first seven novels of the Harry Potter series
library(tm.plugin.webmining)
install.packages("tm.plugin.webmining")
library(tm.plugin.webmining)
acq
data("acq")
tm::acq
library(tm)
data("acq")
data("acq")
acq
acq[[1]]
(tidy_acq <- tidy(acq))
tidy_acq %>% filter(!is.na(author))
tidy_acq %>% mutate(lubridate::year(datetimestamp))
tidy_acq %>% mutate(year = lubridate::year(datetimestamp)) %>% unique(year)
tidy_acq %>% mutate(year = lubridate::year(datetimestamp)) %>% select(year)
tidy_acq %>% mutate(year = lubridate::year(datetimestamp)) %>% select(year) %>% unique($year)
tidy_acq %>% mutate(year = lubridate::year(datetimestamp)) %>% select(year) %>% unique(.$year)
tidy_acq %>% mutate(year = lubridate::year(datetimestamp)) %>% select(year) %>% distinct(year)
tidy(acq[[2]])
